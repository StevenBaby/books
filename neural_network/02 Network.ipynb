{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 神经网络\n",
    "\n",
    "## 参考\n",
    "\n",
    "- <https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def backward(self, dy):\n",
    "        pass\n",
    "\n",
    "    def update(self, lr=0.1):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(x, w)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, w = sympy.symbols(\"x, w\")\n",
    "x, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle w$"
      ],
      "text/plain": [
       "w"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx = sympy.diff(x * w, x)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(Layer):\n",
    "\n",
    "    def __init__(self, input, output) -> None:\n",
    "        self.w = np.random.normal(\n",
    "            loc=0.0,\n",
    "            scale=pow(input, -0.5),\n",
    "            size=(input, output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        y = np.dot(x, self.w)\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        dx = np.dot(dy, self.w.T)\n",
    "        self.dw = np.dot(self.x.reshape(-1, 1), dy.reshape(1, -1))\n",
    "        return dx\n",
    "\n",
    "    def update(self, lr=0.1):\n",
    "        self.w += lr * self.dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [-0.3932558   0.18136254 -0.0159218 ]\n",
      "dx: [-0.10257795  0.0649937 ]\n",
      "dw: [[ 0.03  0.06 -0.09]\n",
      " [ 0.05  0.1  -0.15]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.3, 0.5])\n",
    "dy = np.array([0.1, 0.2, -0.3])\n",
    "layer = LinearLayer(2, 3)\n",
    "y = layer.forward(x)\n",
    "print(\"y:\", y)\n",
    "\n",
    "dx = layer.backward(dy)\n",
    "print(\"dx:\", dx)\n",
    "print(\"dw:\", layer.dw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle y = \\frac{1}{1 + e^{- x}}$"
      ],
      "text/plain": [
       "Eq(y, 1/(1 + exp(-x)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sympy.symbols(\"x\")\n",
    "y = 1 / (1 + sympy.exp(-x))\n",
    "sympy.Eq(sympy.Symbol('y'), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{e^{- x}}{\\left(1 + e^{- x}\\right)^{2}}$"
      ],
      "text/plain": [
       "exp(-x)/(1 + exp(-x))**2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.diff(y, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{aligned}\n",
    "& e^{-x} \\over (1 + e^{-x})^2  \\\\\n",
    "=&  {1 \\over 1 + e^{-x}}  \\cdot {e^{-x} \\over 1 + e^{-x} } \\\\\n",
    "=&  {1 \\over 1 + e^{-x}}  \\cdot {1 + e^{-x} - 1 \\over 1 + e^{-x} } \\\\\n",
    "=&  {1 \\over 1 + e^{-x}}  \\cdot \\left(1 -  {1 \\over 1 + e^{-x}}\\right) \\\\\n",
    "=& y * (1 - y)\n",
    "\\end{aligned}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer(Layer):\n",
    "\n",
    "    def forward(self, x):\n",
    "        # scipy.special.expit(x)\n",
    "        self.y = 1 / (1 + np.exp(-x))\n",
    "        return self.y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        dx = dy * (1.0 - self.y) * self.y\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = LinearLayer(2, 3)\n",
    "layer2 = SigmoidLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:01<00:00, 53775.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01244283, 0.01244231, 0.98755844])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.3, 0.5])\n",
    "t = np.array([0.0, 0.0, 1.0])\n",
    "\n",
    "epoch = 100000\n",
    "bar = tqdm(range(epoch))\n",
    "\n",
    "for _ in bar:\n",
    "    y = layer1.forward(x)\n",
    "    y = layer2.forward(y)\n",
    "\n",
    "    dy = t - y\n",
    "\n",
    "    dx = layer2.backward(dy)\n",
    "    layer1.backward(dx)\n",
    "    layer1.update()\n",
    "\n",
    "y = layer1.forward(x)\n",
    "y = layer2.forward(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "\n",
    "    def __init__(self, input, hidden, output) -> None:\n",
    "        self.layers = [\n",
    "            LinearLayer(input, hidden),\n",
    "            SigmoidLayer(),\n",
    "            LinearLayer(hidden, output),\n",
    "            SigmoidLayer(),\n",
    "        ]\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dy):\n",
    "        for layer in self.layers[::-1]:\n",
    "            dy = layer.backward(dy)\n",
    "        return dy\n",
    "\n",
    "    def update(self, lr=0.1):\n",
    "        for layer in self.layers[::-1]:\n",
    "            layer.update(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.] [0.47576226 0.53161721] 1 0\n",
      "[0. 1.] [0.44784662 0.56425225] 1 1\n",
      "[1. 0.] [0.48221704 0.49349152] 1 1\n",
      "[1. 1.] [0.46289581 0.52574148] 1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:14<00:00, 7028.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.] [0.98397524 0.01598661] 0 0\n",
      "[0. 1.] [0.01572814 0.98430291] 1 1\n",
      "[1. 0.] [0.01586148 0.98415649] 1 1\n",
      "[1. 1.] [0.98436763 0.01562395] 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetwork(2, 30, 2)\n",
    "\n",
    "x_batch = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "    [1.0, 0.0],\n",
    "    [1.0, 1.0],\n",
    "])\n",
    "t_batch = np.array([\n",
    "    [0.99, 0.01],\n",
    "    [0.01, 0.99],\n",
    "    [0.01, 0.99],\n",
    "    [0.99, 0.01],\n",
    "])\n",
    "\n",
    "for i in range(4):\n",
    "    y = net.forward(x_batch[i])\n",
    "    print(x_batch[i], y, np.argmax(y), np.argmax(t_batch[i]))\n",
    "\n",
    "epoch = 100000\n",
    "bar = tqdm(range(epoch))\n",
    "for _ in bar:\n",
    "    for i in range(4):\n",
    "        y = net.forward(x_batch[i])\n",
    "        dy = t_batch[i] - y\n",
    "        # loss = sum(dy ** 2)\n",
    "        dx = net.backward(dy)\n",
    "        net.update()\n",
    "        # bar.set_postfix(dict(loss=f\"{loss}\"))\n",
    "\n",
    "for i in range(4):\n",
    "    y = net.forward(x_batch[i])\n",
    "    print(x_batch[i], y, np.argmax(y), np.argmax(t_batch[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4a7866b55a66abc857b03408de44c5c223dfa656b814ba5aeb66f9babea1100"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
